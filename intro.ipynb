{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch as tch\n",
    "from torch import autograd as agd\n",
    "import torch.nn as tchnn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optm\n",
    "from torchvision import transforms, utils\n",
    "import torchvision\n",
    "import os\n",
    "import struct\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-1.1848e-26  4.5723e-41 -1.1848e-26  4.5723e-41  0.0000e+00  0.0000e+00\n",
      " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      " 0.0000e+00  1.6255e-43  1.1351e-43  0.0000e+00 -1.1848e-26  4.5723e-41\n",
      "-9.3544e+23  3.0644e-41 -9.6731e+23  3.0644e-41  6.8664e-44  0.0000e+00\n",
      "[torch.FloatTensor of size 6x6]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a1 = tch.Tensor(6,6)\n",
    "print(a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0.5872  0.0279  0.2313  0.7905  0.6577  0.2489\n",
      " 0.2529  0.5860  0.6877  0.0157  0.0138  0.8735\n",
      " 0.3973  0.4544  0.8631  0.1011  0.8682  0.9558\n",
      " 0.8635  0.8142  0.7106  0.5953  0.2627  0.2349\n",
      " 0.5930  0.7063  0.4601  0.6565  0.9937  0.9896\n",
      " 0.0301  0.0464  0.7377  0.4010  0.6787  0.2290\n",
      "[torch.FloatTensor of size 6x6]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a2 = tch.rand(6,6)\n",
    "print(a2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 5.8718e-01  2.7909e-02  2.3126e-01  7.9054e-01  6.5769e-01  2.4894e-01\n",
       " 2.5286e-01  5.8600e-01  6.8771e-01  1.5668e-02  1.3766e-02  8.7353e-01\n",
       " 3.9733e-01  4.5444e-01  8.6311e-01  1.0108e-01  8.6817e-01  9.5584e-01\n",
       " 8.6352e-01  8.1424e-01  7.1055e-01  5.9526e-01  2.6272e-01  2.3491e-01\n",
       " 5.9304e-01  7.0627e-01  4.6010e-01  6.5651e-01  9.9366e-01  9.8962e-01\n",
       "-9.3544e+23  4.6384e-02 -9.6731e+23  4.0097e-01  6.7866e-01  2.2904e-01\n",
       "[torch.FloatTensor of size 6x6]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1+a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 30])\n"
     ]
    }
   ],
   "source": [
    "m = tch.nn.Linear(20, 30)\n",
    "input = autograd.Variable(torch.randn(128, 20))\n",
    "output = m(input)\n",
    "print(output.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LeNet5(tchnn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.C1 = tchnn.Conv2d(1,6,5) #in-channel, out-channel, kernel-size\n",
    "        self.C3 = tchnn.Conv2d(6,16,5)\n",
    "        self.C5 = tchnn.Conv2d(16,120,5)\n",
    "        self.F6 = tchnn.Linear(120,84)\n",
    "        self.Ou = tchnn.Linear(84,10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #print('dbg ', x.size())\n",
    "        x = F.max_pool2d(F.relu(self.C1(x)), 2) #till S2\n",
    "        #print('dbg ', x.size())\n",
    "        x = F.max_pool2d(F.relu(self.C3(x)), 2) #till S4\n",
    "        #print('dbg ', x.size())\n",
    "        x = F.relu(self.C5(x)) #till C5\n",
    "        x = x.view(-1, 120)\n",
    "        #print('dbg ', x.size())\n",
    "        x = F.relu(self.F6(x))\n",
    "        #print('dbg ', x.size())\n",
    "        x = F.relu(self.Ou(x))\n",
    "        #print('dbg ', x.size())\n",
    "        return x\n",
    "        \n",
    "    def name(self):\n",
    "        return 'LeNet5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LeNet5().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet5 (\n",
      "  (C1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (C3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (C5): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (F6): Linear (120 -> 84)\n",
      "  (Ou): Linear (84 -> 10)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = optm.SGD(model.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loading data\n",
    "import os\n",
    "import struct\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def read(dataset = \"training\", path = \".\"):\n",
    "    \"\"\"\n",
    "    Python function for importing the MNIST data set.  It returns an iterator\n",
    "    of 2-tuples with the first element being the label and the second element\n",
    "    being a numpy.uint8 2D array of pixel data for the given image.\n",
    "    \"\"\"\n",
    "\n",
    "    if dataset is \"training\":\n",
    "        fname_img = os.path.join(path, 'train-images.idx3-ubyte')\n",
    "        fname_lbl = os.path.join(path, 'train-labels.idx1-ubyte')\n",
    "    elif dataset is \"testing\":\n",
    "        fname_img = os.path.join(path, 't10k-images.idx3-ubyte')\n",
    "        fname_lbl = os.path.join(path, 't10k-labels.idx1-ubyte')\n",
    "    else:\n",
    "        print(\"dataset must be 'testing' or 'training'\")\n",
    "\n",
    "    # Load everything in some numpy arrays\n",
    "    with open(fname_lbl, 'rb') as flbl:\n",
    "        magic, num = struct.unpack(\">II\", flbl.read(8))\n",
    "        lbl = np.fromfile(flbl, dtype=np.int8)\n",
    "\n",
    "    with open(fname_img, 'rb') as fimg:\n",
    "        magic, num, rows, cols = struct.unpack(\">IIII\", fimg.read(16))\n",
    "        img = np.fromfile(fimg, dtype=np.uint8).reshape(len(lbl), rows, cols)\n",
    "\n",
    "    get_img = lambda idx: (lbl[idx], img[idx])\n",
    "\n",
    "    # Create an iterator which returns each image in turn\n",
    "    for i in range(len(lbl)):\n",
    "        yield get_img(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = list(read(dataset='training', path='./MNIST_data'))\n",
    "test_data = list(read(dataset='testing', path='./MNIST_data'))\n",
    "#making data 32X32\n",
    "train_data32 = []\n",
    "test_data32 = []\n",
    "for x in train_data:\n",
    "    img = np.zeros([32,32])\n",
    "    img[2:30,2:30] = x[1]\n",
    "    train_data32.append((x[0],img))\n",
    "for x in test_data:\n",
    "    img = np.zeros([32,32])\n",
    "    img[2:30,2:30] = x[1]\n",
    "    test_data32.append((x[0],img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data32[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngvo/Py0mvrWABTMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7528276da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_data32[0][1], cmap=mpl.cm.Greys)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQoAAAD8CAYAAACPd+p5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f752812b0f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = np.zeros([4,4])\n",
    "a[1:3,1:3] = np.ones([2,2])\n",
    "plt.imshow(a)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0\n",
       " 0\n",
       "[torch.FloatTensor of size 2]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tch.FloatTensor(np.zeros(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "class MNISTLoader(tch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, dataset='training', root_dir='.', transform=None):\n",
    "        if dataset=='training':\n",
    "            self.fname = os.path.join(root_dir, 'train-images.idx3-ubyte')\n",
    "            self.flblname = os.path.join(root_dir, 'train-labels.idx1-ubyte')\n",
    "        elif dataset=='testing':\n",
    "            self.fname = os.path.join(root_dir, 't10k-images.idx3-ubyte')\n",
    "            self.flblname = os.path.join(root_dir, 't10k-labels.idx1-ubyte')\n",
    "        else:\n",
    "            print('dataset must be either training or testing')\n",
    "        self.transform = transform\n",
    "        \n",
    "        with open(self.flblname, 'rb') as flbl:\n",
    "            magic, num = struct.unpack(\">II\", flbl.read(8))\n",
    "            self.lbl = np.fromfile(flbl, dtype=np.uint8)\n",
    "        with open(self.fname, 'rb') as fimg:\n",
    "            magic, num, rows, cols = struct.unpack(\">IIII\", fimg.read(16))\n",
    "            self.img28 = np.fromfile(fimg, dtype=np.uint8).reshape(len(self.lbl), rows, cols)\n",
    "        self.lbl = tch.LongTensor(self.lbl)\n",
    "        self.img28 = tch.ByteTensor(self.img28)\n",
    "            \n",
    "    def __len__(self):\n",
    "        if dataset=='training':\n",
    "            return 60000\n",
    "        else:\n",
    "            return 10000\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "            img28, target = self.img28[idx], self.lbl[idx]\n",
    "            img28 = PIL.fromarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainData = MNISTLoader(root_dir='./MNIST_data', transform = transforms.Normalize(0.5,1.0))\n",
    "testData = MNISTLoader(dataset='testing', root_dir='./MNIST_data', transform = transforms.Normalize(0.5,1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "zip argument #2 must support iteration",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-385e89e13df1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtestData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-89-be9dcaa34c8d>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             return (tch.squeeze(tch.from_numpy(np.array([self.lbl[idx]])).long()), \n\u001b[0;32m---> 33\u001b[0;31m                     self.transform(tch.unsqueeze(tch.from_numpy(self.img32[idx]).float(),0)))\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlbl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg32\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Misc/anaconda3/lib/python3.6/site-packages/torchvision-0.1.9-py3.6.egg/torchvision/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    153\u001b[0m         \"\"\"\n\u001b[1;32m    154\u001b[0m         \u001b[0;31m# TODO: make efficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m             \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: zip argument #2 must support iteration"
     ]
    }
   ],
   "source": [
    "testData[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0\n",
       " 0\n",
       " 0\n",
       "[torch.DoubleTensor of size 3]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tch.autograd.Variable(tch.from_numpy(np.zeros(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batchSize = 128\n",
    "train_loader = tch.utils.data.DataLoader(dataset=trainData, batch_size=batchSize, shuffle=True, num_workers=1, pin_memory=True)\n",
    "test_loader = tch.utils.data.DataLoader(dataset=testData, batch_size=batchSize, shuffle=False, num_workers=1, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>>> total trainning batch number: 469\n",
      "==>>> total testing batch number: 79\n"
     ]
    }
   ],
   "source": [
    "print('==>>> total trainning batch number: {}'.format(len(train_loader)))\n",
    "print('==>>> total testing batch number: {}'.format(len(test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training on cuda\n",
    "model = LeNet5().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeNet5 (\n",
       "  (C1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (C3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (C5): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (F6): Linear (120 -> 84)\n",
       "  (Ou): Linear (84 -> 10)\n",
       ")"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>>> epoch: 0, batch index: 0, train loss: 2.30258489\n",
      "==>>> epoch: 0, batch index: 100, train loss: 2.30258489\n",
      "==>>> epoch: 0, batch index: 200, train loss: 2.30258489\n",
      "==>>> epoch: 0, batch index: 300, train loss: 2.30258489\n",
      "==>>> epoch: 0, batch index: 400, train loss: 2.30258489\n",
      "==>>> epoch: 1, batch index: 0, train loss: 2.30258489\n",
      "==>>> epoch: 1, batch index: 100, train loss: 2.30258489\n",
      "==>>> epoch: 1, batch index: 200, train loss: 2.30258489\n",
      "==>>> epoch: 1, batch index: 300, train loss: 2.30258489\n",
      "==>>> epoch: 1, batch index: 400, train loss: 2.30258489\n",
      "==>>> epoch: 2, batch index: 0, train loss: 2.30258489\n",
      "==>>> epoch: 2, batch index: 100, train loss: 2.30258489\n",
      "==>>> epoch: 2, batch index: 200, train loss: 2.30258489\n",
      "==>>> epoch: 2, batch index: 300, train loss: 2.30258489\n",
      "==>>> epoch: 2, batch index: 400, train loss: 2.30258489\n",
      "==>>> epoch: 3, batch index: 0, train loss: 2.30258489\n",
      "==>>> epoch: 3, batch index: 100, train loss: 2.30258489\n",
      "==>>> epoch: 3, batch index: 200, train loss: 2.30258489\n",
      "==>>> epoch: 3, batch index: 300, train loss: 2.30258489\n",
      "==>>> epoch: 3, batch index: 400, train loss: 2.30258489\n",
      "==>>> epoch: 4, batch index: 0, train loss: 2.30258489\n",
      "==>>> epoch: 4, batch index: 100, train loss: 2.30258489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-70:\n",
      "Traceback (most recent call last):\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-f184c6633959>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0magd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m#print(batch_idx, X.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Misc/anaconda3/lib/python3.6/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36m_cuda\u001b[0;34m(self, device, async)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mnew_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/udion/Misc/anaconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/udion/Misc/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/udion/Misc/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 40, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/udion/Misc/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 40, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"<ipython-input-59-ba3e6c8e7970>\", line 31, in __getitem__\n",
      "    return (tch.squeeze(tch.from_numpy(np.array([self.lbl[idx]])).long()), tch.unsqueeze(tch.from_numpy(self.img32[idx]).float(),0))\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "optimizer = optm.SGD(model.parameters(), lr=0.0005, momentum=0.0001)\n",
    "#print(list(model.parameters()))\n",
    "for epoch in range(10):\n",
    "    #training\n",
    "    for batch_idx, (labels,X) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        labels,X = agd.Variable(labels.cuda()),agd.Variable(X.cuda())\n",
    "        labels = tch.squeeze(labels)\n",
    "        #print(batch_idx, X.size())\n",
    "        outp = model(X)\n",
    "        #print(list(model.parameters()))\n",
    "        loss = F.cross_entropy(outp, labels)\n",
    "        #print(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #print(model.parameters())\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('==>>> epoch: {}, batch index: {}, train loss: {:.8f}'.format(epoch, batch_idx, loss.data[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
